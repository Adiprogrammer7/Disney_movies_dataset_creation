{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scraping data for disney movies from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get info box of a single movie wiki page.\n",
    "\n",
    "# sometimes there are multiple values in <td> and we want them to be in list, for that this function.\n",
    "def get_td_values(td_tag): #this function will be called by function 'get_info_box'\n",
    "    if td_tag.find('li'):  #when <td> has multiple values in <li> tags.\n",
    "        #returning a list via list comprehension.\n",
    "        return [li.get_text(' ', strip= True).replace('\\xa0', ' ') for li in td_tag.find_all('li')] \n",
    "    elif td_tag.find('br'): #when <td> has multiple values in <br> tags.\n",
    "        return [text for text in td_tag.stripped_strings] #strings separated by <br> are now in list.\n",
    "    else:  #when <td> has only one content.\n",
    "        return td_tag.get_text(' ', strip= True).replace('\\xa0', ' ')\n",
    "        \n",
    "def clean_tags(soup_obj):\n",
    "    for tag in soup_obj.find_all(['sup', 'span']): #cleaning some tags whose content we don't want via get_text()\n",
    "        tag.decompose()\n",
    "        \n",
    "def get_info_box(url):\n",
    "    \n",
    "    source = requests.get(url).content\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    info_box = soup.find('table', class_= 'infobox vevent')\n",
    "    all_tr = info_box.find_all('tr') #getting all table rows where our content lies.\n",
    "    clean_tags(soup)\n",
    "    \n",
    "    movie_info = {}\n",
    "    for index, each_row in enumerate(all_tr):\n",
    "        if index == 0:\n",
    "            movie_info['Title'] = each_row.find('th').get_text(' ', strip= True)\n",
    "        else:\n",
    "            header = each_row.find('th')\n",
    "            if header:\n",
    "                row_key = each_row.find('th').get_text(' ', strip= True) #words in th will be joined by space and whitespace will be gone\n",
    "                row_content = get_td_values(each_row.find('td')) #calling a function on <td>.\n",
    "                movie_info[row_key] = row_content \n",
    "    return movie_info\n",
    "# get_info_box('https://en.wikipedia.org/wiki/Ponyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'find'\n",
      "Zorro the Avenger\n",
      "'NoneType' object has no attribute 'find'\n",
      "The Sign of Zorro\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "True-Life Adventures\n"
     ]
    }
   ],
   "source": [
    "# Code to loop through list of disney movies and run above function on each movie page.\n",
    "source = requests.get('https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films').content\n",
    "soup = BeautifulSoup(source, 'html.parser')\n",
    "movies_info_list = [] \n",
    "base_url = 'https://en.wikipedia.org/'\n",
    "movies_list = soup.select('.wikitable.sortable i a') #it is finding 'wikitable sortable' class in that, finds <i> having <a> tag. \n",
    "for movie in movies_list:\n",
    "    try:\n",
    "        relative_url = movie['href']\n",
    "        full_url = base_url + relative_url\n",
    "        movies_info_list.append(get_info_box(full_url))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(movie.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_info_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving/loading scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, data):\n",
    "    with open(filename, 'w', encoding= 'utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii= False, indent= 2)\n",
    "        \n",
    "def load_data(filename):\n",
    "    with open(filename, encoding= 'utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('disney_movies_data.json', movies_info_list) #saving data in json so can be accessed easily next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access saved data\n",
    "movies_info_list = load_data('disney_movies_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Running time conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes movie dict and gives int if 'Running time' present in dict.\n",
    "def int_running_time(movie):\n",
    "    if 'Running time' in movie.keys(): #if there is running time.\n",
    "        if isinstance(movie['Running time'], list): #when running time is in list with multiple values.\n",
    "            return int(movie['Running time'][0].split(' ')[0]) #for just int \n",
    "        else:  #no list just single value\n",
    "            return int(movie['Running time'].split(' ')[0])\n",
    "    return None  #when movie dict has no 'Running time'.      \n",
    "\n",
    "for movie in movies_info_list:\n",
    "    movie['Running Time(Min)'] = int_running_time(movie) #new key added to dict.\n",
    "\n",
    "save_data('disney_movies_data.json', movies_info_list) #saving modifications made in variable 'movies_info_list'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Money conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "num = r'\\d+(,\\d{3})*\\.*\\d*' #'856', '122,322', '12.7' etc.\n",
    "word = r'(thousand|million|billion)' \n",
    "money_num = fr'\\${num}' \n",
    "money_num_word = fr'{money_num}(-|\\sto\\s|â€“)?({num})?\\s{word}'  #fr'' for both formatted and raw string.\n",
    "\n",
    "def money_word_conversion(string_word): #takes thousand,million,billion can gives their num factors.\n",
    "    money_word_dict = {'thousand': 1000, 'million': 1000000, 'billion': 1000000000}\n",
    "    return money_word_dict.get(string_word.lower(), 1)  #if string_word not in dict, return 1.\n",
    "\n",
    "\n",
    "# takes diff. forms of money like '$856', '$122,322', '$12.7 million' and returns its single number value.\n",
    "def money_conversion(money):\n",
    "    if money == 'N/A':\n",
    "        return None\n",
    "    \n",
    "    if isinstance(money, list):  #when there are multiple money values given in a list.\n",
    "        money = money[0]\n",
    "\n",
    "    #if there is match along with money word like '$12.7 million'\n",
    "    if re.search(money_num_word, money, flags= re.I):  #flags= re.I ignores case of word. \n",
    "        string_match = re.search(money_num_word, money, flags= re.I).group()\n",
    "        string_num = re.search(num, string_match).group() #finding only num from entire string match. \n",
    "        string_word = re.search(word, string_match, flags= re.I).group() #only money word from entire string match. \n",
    "        return (float(string_num.replace(',', '')) * money_word_conversion(string_word))\n",
    "\n",
    "    #without money word like '$122,322'\n",
    "    elif re.search(money_num, money): \n",
    "        string_num = re.search(num, money).group() \n",
    "        return float(string_num.replace(',', '')) #returning float money without unwanted chars. \n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning diff. forms of money values into a single float values in new dict keys.\n",
    "for movie in movies_info_list:\n",
    "    movie['Budget($)'] = money_conversion(movie.get('Budget', 'N/A'))\n",
    "    movie['Box office($)'] = money_conversion(movie.get('Box office', 'N/A'))\n",
    "\n",
    "save_data('disney_movies_data.json', movies_info_list) #saving modifications made in variable 'movies_info_list'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Datetime cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def date_cleaning(date): #removing brackets and all uneccessry stuff.\n",
    "    return date.split('(')[0].strip() #.strip() strips whitespaces from start and end.\n",
    "\n",
    "def date_conversion(date):\n",
    "    if isinstance(date, list): \n",
    "        date = date[0]\n",
    "    if date == 'N/A':\n",
    "        return None\n",
    "    \n",
    "    date_str = date_cleaning(date)\n",
    "    \n",
    "    date_formats = ['%B %d, %Y', '%d %B %Y']  #trying different formats that are present to be converted in datetime obj.\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).date()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            \n",
    "    return None\n",
    "    \n",
    "# date_conversion('23 December 2017 ( Spencer House )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movies_info_list:\n",
    "    movie['Release date(datetime)'] = date_conversion(movie.get('Release date', 'N/A')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use pickle to save our data as jason doesn't allow datetime objects.\n",
    "import pickle\n",
    "\n",
    "def pickle_save(filename, data):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save('cleaned_disney_movies_data.pickle', movies_info_list) #saving modifications done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Attaching IMDB, Rotten Tomatoes and metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = pickle_load('cleaned_disney_movies_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os #as we will be using local envirnment vars for api key.\n",
    "\n",
    "def get_omdb_info(title):\n",
    "    base_url = 'http://www.omdbapi.com/?'\n",
    "    parameters = {'apikey': os.environ['omdb_api_key'], 't':title} #according to api these parameters will be required\n",
    "    params_encoded = urllib.parse.urlencode(parameters) #joining parameters in url form.\n",
    "    full_url = base_url + params_encoded\n",
    "    return requests.get(full_url).json()  #to get the html response in json format\n",
    "\n",
    "def get_rotten_tomatoes(omdb_info):\n",
    "    ratings = omdb_info.get('Ratings', [])\n",
    "    for rating in ratings:\n",
    "        if rating['Source'] == 'Rotten Tomatoes':\n",
    "            return rating['Value']\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movies_data:\n",
    "    title = movie['Title']\n",
    "    omdb_info = get_omdb_info(title)\n",
    "    movie['IMDB score'] = omdb_info.get('imdbRating', None)\n",
    "    movie['Metascore'] = omdb_info.get('Metascore', None)\n",
    "    movie['Rotten Tomatoes'] = get_rotten_tomatoes(omdb_info)\n",
    "    print('s')\n",
    "\n",
    "pickle_save('cleaned_disney_movies_data.pickle', movies_data) #saving modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Final saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data_copy = [movie.copy() for movie in movies_data] #as lists are mutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy way to get it into csv :)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(movies_data_copy)\n",
    "df.to_csv('disney_movies_data_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
